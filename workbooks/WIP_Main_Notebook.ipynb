{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Guiding question:** What are the top 5 zip codes based on the ROI for the cit of Pittsburgh?\n",
    ">\n",
    ">\n",
    "> **Evaluation Metric:** ROI/Risk\n",
    ">\n",
    ">\n",
    "> **Dataset:** Zillow data from 1996-2018\n",
    ">\n",
    ">\n",
    "> **Goal:** time series modeling for each zip code to calculate forecasted sale prices.\n",
    ">\n",
    ">\n",
    "> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Workflow: Start -> Finish**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:54.399178Z",
     "start_time": "2021-08-23T21:31:51.858468Z"
    }
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "## Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import pmdarima as pmd\n",
    "\n",
    "## Settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(12,6)\n",
    "plt.style.use('seaborn-talk')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "pd.set_option('max_rows', 100)\n",
    "\n",
    "from bmc_functions import eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:54.506976Z",
     "start_time": "2021-08-23T21:31:54.401050Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:55.176464Z",
     "start_time": "2021-08-23T21:31:54.509361Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading data\n",
    "source = '../data/zillow_data.csv'\n",
    "data = pd.read_csv(source)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:55.317387Z",
     "start_time": "2021-08-23T21:31:55.178462Z"
    }
   },
   "outputs": [],
   "source": [
    "## Initial inspection\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Subset of Zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The dataset is much larger than I need for my purposes, so I will select only the zip codes for the Pittsburgh Metro area.\n",
    ">\n",
    ">\n",
    "> To select this data, I will filter the initial dataframe by selecting \"Pittsburgh\" from the \"city\" column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:55.584599Z",
     "start_time": "2021-08-23T21:31:55.319389Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Selecting the city of Pittsburgh \n",
    "\n",
    "pitt_df = data[data['City'] == 'Pittsburgh']\n",
    "pitt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:56.534349Z",
     "start_time": "2021-08-23T21:31:55.586569Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Examining Statistics for the city of Pittsburgh \n",
    "eda.report_df(pitt_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:56.644683Z",
     "start_time": "2021-08-23T21:31:56.536336Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Inspecting overall data for CA - transposed and dropping RegionID, SizeRank\n",
    "\n",
    "# pitt_zips = pitt_df.pivot_table(index= 'RegionName').T[:-2]\n",
    "# pitt_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:56.740633Z",
     "start_time": "2021-08-23T21:31:56.647654Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_datetimes(df):\n",
    "#     \"\"\"\n",
    "#     Takes a dataframe:\n",
    "#     returns only those column names that can be converted into datetime objects \n",
    "#     as datetime objects.\n",
    "#     NOTE number of returned columns may not match total number of columns in passed dataframe\n",
    "#     \"\"\"\n",
    "    \n",
    "#     return pd.to_datetime(df.columns.values[7:], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:57.009228Z",
     "start_time": "2021-08-23T21:31:56.742589Z"
    }
   },
   "outputs": [],
   "source": [
    "# pitt_df.columns.values[7:] = get_datetimes(pitt_df)\n",
    "# pitt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:57.117693Z",
     "start_time": "2021-08-23T21:31:57.011239Z"
    }
   },
   "outputs": [],
   "source": [
    "def melt_data(df):\n",
    "    \"\"\"\n",
    "    Takes the zillow_data dataset in wide form or a subset of the zillow_dataset.  \n",
    "    Returns a long-form datetime dataframe with the datetime column names\n",
    "    as the index and the values as the 'values' column.\n",
    "    \n",
    "    If more than one row is passes in the wide-form dataset, the values column\n",
    "    will be the mean of the values from the datetime columns in all of the rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    melted = pd.melt(df, id_vars=['RegionName', 'RegionID', 'SizeRank',\n",
    "                                  'City', 'State', 'Metro', 'CountyName'],\n",
    "                     var_name='time')\n",
    "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "    melted = melted.dropna(subset=['value'])\n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:57.259105Z",
     "start_time": "2021-08-23T21:31:57.119804Z"
    }
   },
   "outputs": [],
   "source": [
    "pitt_melted = melt_data(pitt_df)\n",
    "pitt_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T/T Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T23:39:54.444073Z",
     "start_time": "2021-08-23T23:39:54.439092Z"
    }
   },
   "outputs": [],
   "source": [
    "def ts_spilt(timeseries_df, threshold):\n",
    "    tts_cutoff = round(ts.shape[0]*threshold)\n",
    "    train = ts.iloc[:tts_cutoff]\n",
    "    test = ts.iloc[tts_cutoff:]\n",
    "\n",
    "    ## Plot\n",
    "    ax = train.plot(label='Train')\n",
    "    test.plot(label='Test')\n",
    "    ax.legend()\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T14:08:54.773535Z",
     "start_time": "2021-08-24T14:08:54.537000Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5c13ac68b4e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Creating the train/test split datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mts_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpitt_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ts_split' is not defined"
     ]
    }
   ],
   "source": [
    "## Creating the train/test split datasets\n",
    "\n",
    "ts_split(pitt_df, .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ TODO: manually code, then  functionize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity Check (Tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dickey Fuller Test for Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADFuller test and results\n",
    "\n",
    "def adfuller_test_df(ts,index=['AD Fuller Results']):\n",
    "    \"\"\"Returns the AD Fuller Test Results and p-values for the null hypothesis\n",
    "    that there the data is non-stationary (that there is a unit root in the data)\"\"\"\n",
    "    \n",
    "    df_res = tsa.stattools.adfuller(ts)\n",
    "    \n",
    "    names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "    res  = dict(zip(names,df_res[:4]))\n",
    "    \n",
    "    res['p<.05'] = res['p-value']<.05\n",
    "    res['Stationary?'] = res['p<.05']\n",
    "    \n",
    "    if isinstance(index,str):\n",
    "        index = [index]\n",
    "    res_df = pd.DataFrame(res,index=index)\n",
    "    res_df = res_df[['Test Statistic','#Lags Used',\n",
    "                     '# of Observations Used','p-value','p<.05',\n",
    "                    'Stationary?']]\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationarity_check(TS,window=8,plot=True,index=['AD Fuller Results']):\n",
    "    \"\"\"Adapted from https://github.com/learn-co-curriculum/dsc-removing-trends-lab/tree/solution\"\"\"\n",
    "    \n",
    "    # Calculate rolling statistics\n",
    "    roll_mean = TS.rolling(window=window, center=False).mean()\n",
    "    roll_std = TS.rolling(window=window, center=False).std()\n",
    "    \n",
    "    # Perform the Dickey Fuller Test\n",
    "    dftest = adfuller_test_df(TS,index=index)\n",
    "    \n",
    "    if plot:\n",
    "        # Plot rolling statistics:\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        plt.plot(TS, color='blue',label=f'Original (freq={TS.index.freq})')\n",
    "        plt.plot(roll_mean, color='red', label=f'Rolling Mean (window={window})')\n",
    "        plt.plot(roll_std, color='black', label = f'Rolling Std (window={window})')\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Rolling Mean & Standard Deviation')\n",
    "        display(dftest)\n",
    "        plt.show(block=False)\n",
    "        \n",
    "    return dftest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dickey Fuller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = tsa.stattools.adfuller(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "res  = dict(zip(names,df_res[:4]))\n",
    "\n",
    "res['p<.05'] = res['p-value']<.05\n",
    "res['Stationary?'] = res['p<.05']\n",
    "\n",
    "if isinstance(index,str):\n",
    "    index = [index]\n",
    "res_df = pd.DataFrame(res,index=index)\n",
    "res_df = res_df[['Test Statistic','#Lags Used',\n",
    "                 '# of Observations Used','p-value','p<.05',\n",
    "                'Stationary?']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Trends, Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:28.297319Z",
     "start_time": "2021-08-23T20:39:27.905320Z"
    }
   },
   "outputs": [],
   "source": [
    "## Testing on differenced data\n",
    "tz_diff = test_zip.diff().dropna()\n",
    "tz_diff.plot()\n",
    "adfuller_test_df(tz_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:30.462677Z",
     "start_time": "2021-08-23T20:39:30.082680Z"
    }
   },
   "outputs": [],
   "source": [
    "## Log Transform, plot and get adfuller test\n",
    "tz_log = np.log(test_zip)\n",
    "tz_log.plot()\n",
    "adfuller_test_df(tz_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:31.906581Z",
     "start_time": "2021-08-23T20:39:31.492275Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subtract Rolling mean\n",
    "tz_rm = test_zip - test_zip.rolling(window=4).mean()\n",
    "tz_rm.dropna(inplace=True)\n",
    "tz_rm.plot()\n",
    "adfuller_test_df(tz_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:33.668590Z",
     "start_time": "2021-08-23T20:39:33.284575Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Exponentially-Weighted Mean\n",
    "tz_ewm = test_zip-test_zip.ewm(4).mean()\n",
    "tz_ewm.dropna(inplace=True)\n",
    "tz_ewm.plot()\n",
    "adfuller_test_df(tz_ewm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:35.510534Z",
     "start_time": "2021-08-23T20:39:34.913536Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Seasonal Decomposition\n",
    "decomp = seasonal_decompose(test_zip)\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:39.060249Z",
     "start_time": "2021-08-23T20:39:38.961271Z"
    }
   },
   "outputs": [],
   "source": [
    "decomp.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:40.096016Z",
     "start_time": "2021-08-23T20:39:39.986986Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Save seasonal/trend/resid in a dictionary.\n",
    "\n",
    "decomp_dict = {'seasonal': decomp.seasonal,\n",
    "              \"trend\": decomp.trend,\n",
    "              'residuals': decomp.resid}\n",
    "\n",
    "decomp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:41.333720Z",
     "start_time": "2021-08-23T20:39:41.152725Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a list of adfuller results to append\n",
    "results = []\n",
    "## Save results of orig ts\n",
    "results.append(adfuller_test_df(test_zip,index=['Original']))\n",
    "\n",
    "## Loop through decomp dict, \n",
    "for trend, ts_ in decomp_dict.items():\n",
    "    # Fill any missing values, get adfuller result\n",
    "    ts_ = ts_.fillna(0)\n",
    "    res = adfuller_test_df(ts_,index=trend)\n",
    "    results.append(res)\n",
    "\n",
    "    \n",
    "    ## Append res to decomp_stationary\n",
    "\n",
    "## make into a df\n",
    "res_df = pd.concat(results)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ TODO: manually code, then  functionize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF/PACF Check (Tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(ts,figsize=(9,6),lags=52,suptitle=None,sup_y = 1.01):\n",
    "    \"\"\"Plot pacf and acf using statsmodels\"\"\"\n",
    "    fig,axes=plt.subplots(nrows=2,figsize=figsize)\n",
    "    \n",
    "    tsa.graphics.plot_acf(ts,ax=axes[0],lags=lags);\n",
    "    tsa.graphics.plot_pacf(ts,ax=axes[1],lags=lags);\n",
    "    \n",
    "    ## Add grid\n",
    "    [ax.grid(axis='x',which='both') for ax in axes]\n",
    "    \n",
    "    if suptitle is not None:\n",
    "        fig.suptitle(suptitle,y=sup_y,fontweight='bold',fontsize=15)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    return fig,axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ACF/PACF train, train_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Loop through each of the stationarity methods and plot results\n",
    ">\n",
    ">\n",
    "> Post plotting, add comments/review\n",
    ">\n",
    ">\n",
    "> ***Remember:*** Auto-Arima/SARIMAX uses orignal data - **purpose of this exploration** is for EDA/determining the \"d\" value for testing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:28.297319Z",
     "start_time": "2021-08-23T20:39:27.905320Z"
    }
   },
   "outputs": [],
   "source": [
    "tz_diff = test_zip.diff().dropna()\n",
    "tz_diff.plot()\n",
    "adfuller_test_df(tz_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:30.462677Z",
     "start_time": "2021-08-23T20:39:30.082680Z"
    }
   },
   "outputs": [],
   "source": [
    "## Log Transform, plot and get adfuller test\n",
    "tz_log = np.log(test_zip)\n",
    "tz_log.plot()\n",
    "adfuller_test_df(tz_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:31.906581Z",
     "start_time": "2021-08-23T20:39:31.492275Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subtract Rolling mean\n",
    "tz_rm = test_zip - test_zip.rolling(window=4).mean()\n",
    "tz_rm.dropna(inplace=True)\n",
    "tz_rm.plot()\n",
    "adfuller_test_df(tz_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:33.668590Z",
     "start_time": "2021-08-23T20:39:33.284575Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tz_ewm = test_zip-test_zip.ewm(4).mean()\n",
    "tz_ewm.dropna(inplace=True)\n",
    "tz_ewm.plot()\n",
    "adfuller_test_df(tz_ewm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Decomp (Tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for seasonality\n",
    "decomp = tsa.seasonal_decompose(train)\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:35.510534Z",
     "start_time": "2021-08-23T20:39:34.913536Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp = seasonal_decompose(test_zip)\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:39.060249Z",
     "start_time": "2021-08-23T20:39:38.961271Z"
    }
   },
   "outputs": [],
   "source": [
    "decomp.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:40.096016Z",
     "start_time": "2021-08-23T20:39:39.986986Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Save seasonal/trend/resid in a dictionary.\n",
    "\n",
    "decomp_dict = {'seasonal': decomp.seasonal,\n",
    "              \"trend\": decomp.trend,\n",
    "              'residuals': decomp.resid}\n",
    "\n",
    "decomp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:41.333720Z",
     "start_time": "2021-08-23T20:39:41.152725Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a list of adfuller results to append\n",
    "results = []\n",
    "## Save results of orig ts\n",
    "results.append(adfuller_test_df(test_zip,index=['Original']))\n",
    "\n",
    "## Loop through decomp dict, \n",
    "for trend, ts_ in decomp_dict.items():\n",
    "    # Fill any missing values, get adfuller result\n",
    "    ts_ = ts_.fillna(0)\n",
    "    res = adfuller_test_df(ts_,index=trend)\n",
    "    results.append(res)\n",
    "\n",
    "    \n",
    "    ## Append res to decomp_stationary\n",
    "\n",
    "## make into a df\n",
    "res_df = pd.concat(results)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:43.850316Z",
     "start_time": "2021-08-23T20:39:43.278254Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pldot decomp again for convenient comparison\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Arima (Tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T19:46:50.720043Z",
     "start_time": "2021-08-23T19:46:50.349256Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_zip.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:40:59.215395Z",
     "start_time": "2021-08-23T20:40:57.891879Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use auto_arima \n",
    "auto_model = pmd.auto_arima(test_zip.loc['2008':],start_p=0,start_q=0,d=1,\n",
    "                            max_p=3,max_q=3,\n",
    "                            max_P=3,max_Q=3,\n",
    "                            start_P=0,start_Q=0,\n",
    "                            m=12,\n",
    "                            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:40:59.971430Z",
     "start_time": "2021-08-23T20:40:59.218400Z"
    }
   },
   "outputs": [],
   "source": [
    "display(auto_model.summary())\n",
    "auto_model.plot_diagnostics();\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ TODO: manually code, then  functionize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_model(model):\n",
    "    \"\"\"Takes a fit statsmodels model and displays the .summary \n",
    "    and plots the built-in plot.diagnostics()\"\"\"\n",
    "    display(model.summary())\n",
    "    model.plot_diagnostics()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Best Model & Eval (Tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T23:51:20.000210Z",
     "start_time": "2021-08-23T23:51:19.994178Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_plot_best_model(train,start_p=0,max_p=5,start_q=0,max_q=5,d=1,m=52,\n",
    "                         start_P=0,start_Q=0, verbose = True):\n",
    "    \n",
    "    auto_model = pmd.auto_arima(train,start_p=start_p,max_p=max_p,\n",
    "                           start_q=start_q,max_q=max_q,d=d,m=m,\n",
    "                           start_P=start_P,start_Q=start_Q,verbose=verbose)\n",
    "    \n",
    "    display(auto_model.summary())\n",
    "    \n",
    "    best_model = tsa.SARIMAX(train,order=auto_model.order,\n",
    "                             seasonal_order = auto_model.seasonal_order,\n",
    "                             enforce_invertibility=False).fit()\n",
    "    \n",
    "    ## Display Summary + Diagnostics\n",
    "    display(best_model.summary())\n",
    "    best_model.plot_diagnostics();\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return auto_model, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Save `conf_int`, `predicted_mean` - 4cDF\n",
    ">\n",
    ">\n",
    "> Plot Tr, Te, 4cDF\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ TODO: manually code, then  functionize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_and_plot(train, test, final_ts = None, model, last_n_lags=52,\n",
    "                      x_label, y_label, figsize=(10,4)):\n",
    "\n",
    "    ## Get forecast\n",
    "    forecast = model.get_forecast(steps=len(test))\n",
    "\n",
    "    ## Save forecasted mean, upper/lower CI as DF\n",
    "    forecast_df = forecast.conf_int()\n",
    "    forecast_df.columns = ['Lower CI','Upper CI']\n",
    "    forecast_df['Forecast'] = forecast.predicted_mean\n",
    "\n",
    "    # Plotting timeseries data\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    last_n_lags=last_n_lags\n",
    "    \n",
    "    if final_ts is None:\n",
    "        train.iloc[-last_n_lags:].plot(label='Training Data')\n",
    "        test.plot(label='Test Data')\n",
    "    else:\n",
    "        ts.iloc[-last_n_lags:].plot(label='Training Data')\n",
    "        ax.axvline(ts.index[-1],ls=':')\n",
    "\n",
    "    ## Plotting forecast and CI\n",
    "    forecast_df['Forecast'].plot(ax=ax,label='Forecast')\n",
    "    ax.fill_between(forecast_df.index,\n",
    "                    forecast_df['Lower CI'], \n",
    "                    forecast_df['Upper CI'],color='g',alpha=0.3)\n",
    "\n",
    "    ax.set(xlabel=x_label)\n",
    "    ax.set(ylabel=y_label)\n",
    "    ax.legend()\n",
    "    plt.show();\n",
    "    \n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_pred(forecast_or_pred,forecast_label='Forecast'):\n",
    "    \"\"\"Takes a PredictionResultsWrapper from statsmodels\n",
    "    extracts the confidence intervals and predicted mean and returns in a df\"\"\"\n",
    "    forecast_df = forecast_or_pred.conf_int()\n",
    "    forecast_df.columns = ['Lower CI','Upper CI']\n",
    "    forecast_df[forecast_label] = forecast_or_pred.predicted_mean\n",
    "    return forecast_df\n",
    "\n",
    "def plot_forecast_from_df(forecast_df,ts_diff=None,orig_label='True Data',\n",
    "                          forecast_label='Forecast',\n",
    "                          last_n_lags=52,figsize=(10,4)):\n",
    "    \"\"\"Takes a forecast_df from get_df_from_pred and optionally \n",
    "    the training/original time series.\n",
    "    \n",
    "    Plots the original ts, the predicted mean and the \n",
    "    confidence invtervals (using fill between)\"\"\"\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    if ts_diff is not None:\n",
    "        ts_diff.iloc[-last_n_lags:].plot(label='True Data')\n",
    "        \n",
    "   \n",
    "    forecast_df['Forecast'].plot(ax=ax,label=forecast_label)\n",
    "    ax.fill_between(forecast_df.index,\n",
    "                    forecast_df['Lower CI'], \n",
    "                    forecast_df['Upper CI'],color='g',alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set(title=f'Forecasted {ts_diff.name}')\n",
    "    return fig,ax\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Full Dataset for Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If happy with the model's test perforamance, retrain on entire ts and forecast into future\n",
    "## Fit a final model and evaluate\n",
    "final_model = tsa.SARIMAX(ts,order=auto_model.order,\n",
    "                seasonal_order = auto_model.seasonal_order,\n",
    "                enforce_invertibility=False).fit()\n",
    "\n",
    "\n",
    "## Display Summary + Diagnostics\n",
    "display(final_model.summary())\n",
    "final_model.plot_diagnostics();\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get forecast \n",
    "forecast = final_model.get_forecast(steps=len(test))\n",
    "\n",
    "## save forecasted mean and upper/lower ci as df\n",
    "forecast_df = forecast.conf_int()\n",
    "forecast_df.columns = ['Lower CI','Upper CI']\n",
    "forecast_df['Forecast'] = forecast.predicted_mean\n",
    "\n",
    "## Plot\n",
    "last_n_lags=52\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "                      \n",
    "# Plotting Training and test data\n",
    "ts.iloc[-last_n_lags:].plot(label='Training Data')\n",
    "ax.axvline(ts.index[-1],ls=':')\n",
    "# test.plot(label='Test Data')\n",
    "\n",
    "## Plotting Forefcast and CI\n",
    "forecast_df['Forecast'].plot(ax=ax,label='Forecast')\n",
    "ax.fill_between(forecast_df.index,\n",
    "                forecast_df['Lower CI'], \n",
    "                forecast_df['Upper CI'],color='g',alpha=0.3)\n",
    "\n",
    "ax.set(ylabel='Crime Count')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> **Reminder:** the goal is to determine the top 5 best zip codes for investment.\n",
    "> * *Need to define \"best investment\" - ROI, risk, ???*\n",
    ">\n",
    ">\n",
    ">\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display final forecasted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dict 2 Store Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> [See this link](https://www.youtube.com/watch?v=atUym8mOnNc&list=PLFknVelSJiSxSwXifV_ysDg50fzbuTzVt&index=59)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T15:09:39.063591Z",
     "start_time": "2021-08-24T15:09:39.038855Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Old notebook code - DO NOT RUN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-415ac458bc6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Old notebook code - DO NOT RUN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: Old notebook code - DO NOT RUN"
     ]
    }
   ],
   "source": [
    "raise ValueError('Old notebook code - DO NOT RUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mod 4 Project - Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This notebook has been provided to you so that you can make use of the following starter code to help with the trickier parts of preprocessing the Zillow dataset. \n",
    "\n",
    "The notebook contains a rough outline the general order you'll likely want to take in this project. You'll notice that most of the areas are left blank. This is so that it's more obvious exactly when you should make use of the starter code provided for preprocessing. \n",
    "\n",
    "**_NOTE:_** The number of empty cells are not meant to infer how much or how little code should be involved in any given step--we've just provided a few for your convenience. Add, delete, and change things around in this notebook as needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Some Notes Before Starting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This project will be one of the more challenging projects you complete in this program. This is because working with Time Series data is a bit different than working with regular datasets. In order to make this a bit less frustrating and help you understand what you need to do (and when you need to do it), we'll quickly review the dataset formats that you'll encounter in this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Wide Format vs Long Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you take a look at the format of the data in `zillow_data.csv`, you'll notice that the actual Time Series values are stored as separate columns. Here's a sample: \n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-seattle-ds-102819/master/images/df_head.png'>\n",
    "\n",
    "You'll notice that the first seven columns look like any other dataset you're used to working with. However, column 8 refers to the median housing sales values for April 1996, column 9 for May 1996, and so on. This This is called **_Wide Format_**, and it makes the dataframe intuitive and easy to read. However, there are problems with this format when it comes to actually learning from the data, because the data only makes sense if you know the name of the column that the data can be found it. Since column names are metadata, our algorithms will miss out on what dates each value is for. This means that before we pass this data to our ARIMA model, we'll need to reshape our dataset to **_Long Format_**. Reshaped into long format, the dataframe above would now look like:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-seattle-ds-102819/master/images/melted1.png'>\n",
    "\n",
    "There are now many more rows in this dataset--one for each unique time and zipcode combination in the data! Once our dataset is in this format, we'll be able to train an ARIMA model on it. The method used to convert from Wide to Long is `pd.melt()`, and it is common to refer to our dataset as 'melted' after the transition to denote that it is in long format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Helper Functions Provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Melting a dataset can be tricky if you've never done it before, so you'll see that we have provided a sample function, `melt_data()`, to help you with this step below. Also provided is:\n",
    "\n",
    "* `get_datetimes()`, a function to deal with converting the column values for datetimes as a pandas series of datetime objects\n",
    "* Some good parameters for matplotlib to help make your visualizations more readable. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:54.399178Z",
     "start_time": "2021-08-23T21:31:51.858468Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # import warnings\n",
    "# # warnings.filterwarnings('ignore')\n",
    "\n",
    "# ## Data Handling\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# ## Visualizations\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# import statsmodels\n",
    "# import statsmodels.tsa.api as tsa\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# import pmdarima as pmd\n",
    "\n",
    "# ## Settings\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize']=(12,6)\n",
    "# plt.style.use('seaborn-talk')\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "# pd.set_option('max_rows', 100)\n",
    "\n",
    "# from bmc_functions import eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:54.506976Z",
     "start_time": "2021-08-23T21:31:54.401050Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:55.176464Z",
     "start_time": "2021-08-23T21:31:54.509361Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## ImportingReading in-Dta\n",
    "# source = '../data/zillow_data.csv'\n",
    "# data = pd.read_csv(source)\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T13:56:40.637690Z",
     "start_time": "2021-08-24T13:56:40.582827Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "> The dataset is much larger than I need for my purposes, so I will determine a smaller regional subset for analysis.\n",
    ">\n",
    ">\n",
    "> As I am from Pittsburgh, PA, I will select that region for my models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:55.584599Z",
     "start_time": "2021-08-23T21:31:55.319389Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Selecting Pittsburgh Metro Area\n",
    "\n",
    "# pitt_df = data[data['City'] == 'Pittsburgh']\n",
    "# pitt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:56.534349Z",
     "start_time": "2021-08-23T21:31:55.586569Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## Examining Statistics for the Pittsburgh Metro area\n",
    "# eda.report_df(pitt_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:56.644683Z",
     "start_time": "2021-08-23T21:31:56.536336Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Inspecting overall data for CA - transposed and dropping RegionID, SizeRank\n",
    "\n",
    "# pitt_zips = pitt_df.pivot_table(index= 'RegionName').T[:-2]\n",
    "# pitt_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:56.740633Z",
     "start_time": "2021-08-23T21:31:56.647654Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def get_datetimes(df):\n",
    "#     \"\"\"\n",
    "#     Takes a dataframe:\n",
    "#     returns only those column names that can be converted into datetime objects \n",
    "#     as datetime objects.\n",
    "#     NOTE number of returned columns may not match total number of columns in passed dataframe\n",
    "#     \"\"\"\n",
    "    \n",
    "#     return pd.to_datetime(df.columns.values[7:], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:57.009228Z",
     "start_time": "2021-08-23T21:31:56.742589Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pitt_df.columns.values[7:] = get_datetimes(pitt_df)\n",
    "# pitt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Melting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:57.117693Z",
     "start_time": "2021-08-23T21:31:57.011239Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def melt_data(df):\n",
    "#     \"\"\"\n",
    "#     Takes the zillow_data dataset in wide form or a subset of the zillow_dataset.  \n",
    "#     Returns a long-form datetime dataframe with the datetime column names\n",
    "#     as the index and the values as the 'values' column.\n",
    "    \n",
    "#     If more than one row is passes in the wide-form dataset, the values column\n",
    "#     will be the mean of the values from the datetime columns in all of the rows.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     melted = pd.melt(df, id_vars=['RegionName', 'RegionID', 'SizeRank',\n",
    "#                                   'City', 'State', 'Metro', 'CountyName'],\n",
    "#                      var_name='time')\n",
    "#     melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "#     melted = melted.dropna(subset=['value'])\n",
    "#     return melted#.groupby('time').aggregate({'value':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:31:57.259105Z",
     "start_time": "2021-08-23T21:31:57.119804Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pitt_melted = melt_data(pitt_df)\n",
    "# pitt_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Old Code - Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:35:36.795907Z",
     "start_time": "2021-08-23T20:35:36.462880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Inspecting overall data for Pittsburgh\n",
    "\n",
    "# pitt_df.pivot_table(index= 'RegionName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:36:54.861741Z",
     "start_time": "2021-08-23T20:36:54.719714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Inspecting overall data for CA - transposed and dropping RegionID, SizeRank\n",
    "\n",
    "# pitt_zips = pitt_df.pivot_table(index= 'RegionName').T[:-2]\n",
    "# pitt_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Step 3: EDA and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T19:05:22.989044Z",
     "start_time": "2021-08-23T19:05:22.884014Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# font = {'family' : 'normal',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 22}\n",
    "\n",
    "# mpl.rc('font', **font)\n",
    "\n",
    "# # NOTE: if you visualizations are too cluttered to read, try calling 'plt.gcf().autofmt_xdate()'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T21:32:37.664368Z",
     "start_time": "2021-08-23T21:32:36.916297Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Generating initial statistical overview\n",
    "# report = eda.report_df(pitt_df)\n",
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:38:12.681415Z",
     "start_time": "2021-08-23T20:38:12.560843Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Inspecting only zip codes with missing columns\n",
    "# report[report['null_sum'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:38:17.964852Z",
     "start_time": "2021-08-23T20:38:17.854751Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Selecting zipcode with largest number of entries\n",
    "# most_freq_zip = report['count'].sort_values(ascending=False)[:1]\n",
    "# most_freq_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:38:57.568291Z",
     "start_time": "2021-08-23T20:38:57.437321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Checking for missing values pre-visualizing\n",
    "# pitt_zips[15243].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:06.174484Z",
     "start_time": "2021-08-23T20:39:06.062385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test_zip = pitt_zips[15243]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:09.100935Z",
     "start_time": "2021-08-23T20:39:08.771880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Initial visualization of one zipcode\n",
    "# test_zip.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ❌ FIX/REMOVE JMI FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:22.846907Z",
     "start_time": "2021-08-23T20:39:22.718727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Lab Function\n",
    "# # from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# def adfuller_test_df(ts,index=['AD Fuller Results']):\n",
    "#     \"\"\"Returns the AD Fuller Test Results and p-values for the null hypothesis\n",
    "#     that there the data is non-stationary (that there is a unit root in the data)\"\"\"\n",
    "    \n",
    "#     df_res = tsa.stattools.adfuller(ts)\n",
    "    \n",
    "#     names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "#     res  = dict(zip(names,df_res[:4]))\n",
    "    \n",
    "#     res['p<.05'] = res['p-value']<.05\n",
    "#     res['Stationary?'] = res['p<.05']\n",
    "    \n",
    "#     if isinstance(index,str):\n",
    "#         index = [index]\n",
    "#     res_df = pd.DataFrame(res,index=index)\n",
    "#     res_df = res_df[['Test Statistic','#Lags Used',\n",
    "#                      '# of Observations Used','p-value','p<.05',\n",
    "#                     'Stationary?']]\n",
    "#     return res_df\n",
    "\n",
    "\n",
    "\n",
    "# def stationarity_check(TS,window=8,plot=True,index=['AD Fuller Results']):\n",
    "#     \"\"\"Adapted from https://github.com/learn-co-curriculum/dsc-removing-trends-lab/tree/solution\"\"\"\n",
    "    \n",
    "#     # Calculate rolling statistics\n",
    "#     roll_mean = TS.rolling(window=window, center=False).mean()\n",
    "#     roll_std = TS.rolling(window=window, center=False).std()\n",
    "    \n",
    "#     # Perform the Dickey Fuller Test\n",
    "#     dftest = adfuller_test_df(TS,index=index)\n",
    "    \n",
    "#     if plot:\n",
    "#         # Plot rolling statistics:\n",
    "#         fig = plt.figure(figsize=(12,6))\n",
    "#         plt.plot(TS, color='blue',label=f'Original (freq={TS.index.freq})')\n",
    "#         plt.plot(roll_mean, color='red', label=f'Rolling Mean (window={window})')\n",
    "#         plt.plot(roll_std, color='black', label = f'Rolling Std (window={window})')\n",
    "#         plt.legend(loc='best')\n",
    "#         plt.title('Rolling Mean & Standard Deviation')\n",
    "#         display(dftest)\n",
    "#         plt.show(block=False)\n",
    "        \n",
    "#     return dftest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:25.207879Z",
     "start_time": "2021-08-23T20:39:24.809871Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# results = stationarity_check(test_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:28.297319Z",
     "start_time": "2021-08-23T20:39:27.905320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tz_diff = test_zip.diff().dropna()\n",
    "# tz_diff.plot()\n",
    "# adfuller_test_df(tz_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:30.462677Z",
     "start_time": "2021-08-23T20:39:30.082680Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Log Transform, plot and get adfuller test\n",
    "# tz_log = np.log(test_zip)\n",
    "# tz_log.plot()\n",
    "# adfuller_test_df(tz_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:31.906581Z",
     "start_time": "2021-08-23T20:39:31.492275Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Subtract Rolling mean\n",
    "# tz_rm = test_zip - test_zip.rolling(window=4).mean()\n",
    "# tz_rm.dropna(inplace=True)\n",
    "# tz_rm.plot()\n",
    "# adfuller_test_df(tz_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:33.668590Z",
     "start_time": "2021-08-23T20:39:33.284575Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tz_ewm = test_zip-test_zip.ewm(4).mean()\n",
    "# tz_ewm.dropna(inplace=True)\n",
    "# tz_ewm.plot()\n",
    "# adfuller_test_df(tz_ewm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:35.510534Z",
     "start_time": "2021-08-23T20:39:34.913536Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decomp = seasonal_decompose(test_zip)\n",
    "# decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:39.060249Z",
     "start_time": "2021-08-23T20:39:38.961271Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# decomp.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:40.096016Z",
     "start_time": "2021-08-23T20:39:39.986986Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Save seasonal/trend/resid in a dictionary.\n",
    "\n",
    "# decomp_dict = {'seasonal': decomp.seasonal,\n",
    "#               \"trend\": decomp.trend,\n",
    "#               'residuals': decomp.resid}\n",
    "\n",
    "# decomp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:41.333720Z",
     "start_time": "2021-08-23T20:39:41.152725Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Make a list of adfuller results to append\n",
    "# results = []\n",
    "# ## Save results of orig ts\n",
    "# results.append(adfuller_test_df(test_zip,index=['Original']))\n",
    "\n",
    "# ## Loop through decomp dict, \n",
    "# for trend, ts_ in decomp_dict.items():\n",
    "#     # Fill any missing values, get adfuller result\n",
    "#     ts_ = ts_.fillna(0)\n",
    "#     res = adfuller_test_df(ts_,index=trend)\n",
    "#     results.append(res)\n",
    "\n",
    "    \n",
    "#     ## Append res to decomp_stationary\n",
    "\n",
    "# ## make into a df\n",
    "# res_df = pd.concat(results)\n",
    "# res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:39:43.850316Z",
     "start_time": "2021-08-23T20:39:43.278254Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Pldot decomp again for convenient comparison\n",
    "# decomp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Step 5: ARIMA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T19:46:50.720043Z",
     "start_time": "2021-08-23T19:46:50.349256Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_zip.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:40:59.215395Z",
     "start_time": "2021-08-23T20:40:57.891879Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Use auto_arima \n",
    "# auto_model = pmd.auto_arima(test_zip.loc['2008':],start_p=0,start_q=0,d=1,\n",
    "#                             max_p=3,max_q=3,\n",
    "#                             max_P=3,max_Q=3,\n",
    "#                             start_P=0,start_Q=0,\n",
    "#                             m=12,\n",
    "#                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:40:59.971430Z",
     "start_time": "2021-08-23T20:40:59.218400Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# display(auto_model.summary())\n",
    "# auto_model.plot_diagnostics();\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:41:20.725971Z",
     "start_time": "2021-08-23T20:41:20.607000Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tz_diff = test_zip.diff().dropna()\n",
    "# tz_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:46:28.160237Z",
     "start_time": "2021-08-23T20:46:28.015239Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# adfuller_test_df(tz_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:42:06.141350Z",
     "start_time": "2021-08-23T20:41:24.148643Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# am_diff = pmd.auto_arima(test_zip,start_p=0,start_q=0, d=1,\n",
    "#                             max_p=4,max_q=3,\n",
    "#                             max_P=3,max_Q=2,\n",
    "#                             start_P=0,start_Q=0,\n",
    "#                             m=12,\n",
    "#                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T20:42:06.875380Z",
     "start_time": "2021-08-23T20:42:06.143351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# display(am_diff.summary())\n",
    "# am_diff.plot_diagnostics();\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ### From SARIMA Models Lab\n",
    "# import itertools\n",
    "# from tqdm.notebook import trange\n",
    "# # Define the p, d and q parameters to take any value between 0 and 2\n",
    "# ps = list(range(0,4))\n",
    "# ds = list(range(0,2))\n",
    "# qs = list(range(0,3))\n",
    "\n",
    "# # Generate all different combinations of p, q and q triplets\n",
    "# pdq_list = list(itertools.product(ps,ds, qs))\n",
    "# pdq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Loop through pdq_list, make an ARIMA model\n",
    "# # save p,d,q and aic to a model_aic list\n",
    "# model_aics= [['p','d','q','aic']]\n",
    "\n",
    "# ## Make Results into a df and sort by aic\n",
    "# for i in trange(len(pdq_list)):\n",
    "#     p,d,q = pdq_list[i]\n",
    "#     model = tsa.arima.ARIMA(ts,order=(p,d,q),enforce_invertibility=False).fit()\n",
    "#     model_aics.append([p,d,q,model.aic])\n",
    "#     print(f'For ({p},{d},{q}), aic = {model.aic:.3f}')\n",
    "\n",
    "# results = pd.DataFrame(model_aics[1:],columns=model_aics[0]).sort_values('aic')\n",
    "# results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331.009px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
